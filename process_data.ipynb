{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a440643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available data ['annotate', 'dev', 'make_lmdb.py', 'train', 'test']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "from prettytable import PrettyTable\n",
    "from IPython.display import Image\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Activation\n",
    "from tensorflow.keras.layers import Conv1D, Add, MaxPooling1D, BatchNormalization\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "\n",
    "\n",
    "data_path = '/home/ziang/goo'\n",
    "print('Available data', os.listdir(data_path))\n",
    "\n",
    "def read_data(partition):\n",
    "  data = []\n",
    "  for fn in os.listdir(os.path.join(data_path, partition)):\n",
    "    with open(os.path.join(data_path, partition, fn)) as f:\n",
    "      data.append(pd.read_csv(f, index_col=None))\n",
    "  return pd.concat(data)\n",
    "df_train = read_data('train')\n",
    "df_val = read_data('dev')\n",
    "df_test = read_data('test')\n",
    "classes = df_train['family_accession'].value_counts().index.tolist()\n",
    "len(classes)\n",
    "train_sm = df_train.loc[df_train['family_accession'].isin(classes)].reset_index()\n",
    "val_sm = df_val.loc[df_val['family_accession'].isin(classes)].reset_index()\n",
    "test_sm = df_test.loc[df_test['family_accession'].isin(classes)].reset_index()\n",
    "\n",
    "codes = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',\n",
    "         'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
    "\n",
    "def create_dict(codes):\n",
    "  char_dict = {}\n",
    "  for index, val in enumerate(codes):\n",
    "    char_dict[val] = index+1\n",
    "\n",
    "  return char_dict\n",
    "\n",
    "char_dict = create_dict(codes)\n",
    "\n",
    "def integer_encoding(data):\n",
    "  \"\"\"\n",
    "  - Encodes code sequence to integer values.\n",
    "  - 20 common amino acids are taken into consideration\n",
    "    and rest 4 are categorized as 0.\n",
    "  \"\"\"\n",
    "  \n",
    "  encode_list = []\n",
    "  for row in data['sequence'].values:\n",
    "    row_encode = []\n",
    "    for code in row:\n",
    "      row_encode.append(char_dict.get(code, 0))\n",
    "    encode_list.append(np.array(row_encode))\n",
    "  \n",
    "  return encode_list\n",
    "train_encode = integer_encoding(train_sm) \n",
    "val_encode = integer_encoding(val_sm) \n",
    "test_encode = integer_encoding(test_sm) \n",
    "\n",
    "max_length = 2048\n",
    "train_pad = pad_sequences(train_encode, maxlen=max_length, padding='post', truncating='post')\n",
    "val_pad = pad_sequences(val_encode, maxlen=max_length, padding='post', truncating='post')\n",
    "test_pad = pad_sequences(test_encode, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "y_train_le = le.fit_transform(train_sm['family_accession'])\n",
    "y_val_le = le.transform(val_sm['family_accession'])\n",
    "y_test_le = le.transform(test_sm['family_accession'])\n",
    "\n",
    "y_train = to_categorical(y_train_le)\n",
    "y_val = to_categorical(y_val_le)\n",
    "y_test = to_categorical(y_test_le)\n",
    "def display_model_score(model, train, val, test, batch_size):\n",
    "\n",
    "  train_score = model.evaluate(train[0], train[1], batch_size=batch_size, verbose=1)\n",
    "  print('Train loss: ', train_score[0])\n",
    "  print('Train accuracy: ', train_score[1])\n",
    "  print('-'*70)\n",
    "\n",
    "  val_score = model.evaluate(val[0], val[1], batch_size=batch_size, verbose=1)\n",
    "  print('Val loss: ', val_score[0])\n",
    "  print('Val accuracy: ', val_score[1])\n",
    "  print('-'*70)\n",
    "  \n",
    "  test_score = model.evaluate(test[0], test[1], batch_size=batch_size, verbose=1)\n",
    "  print('Test loss: ', test_score[0])\n",
    "  print('Test accuracy: ', test_score[1])\n",
    "def residual_block(data, filters, d_rate):\n",
    "  \"\"\"\n",
    "  _data: input\n",
    "  _filters: convolution filters\n",
    "  _d_rate: dilation rate\n",
    "  \"\"\"\n",
    "\n",
    "  shortcut = data\n",
    "\n",
    "  bn1 = BatchNormalization()(data)\n",
    "  act1 = Activation('relu')(bn1)\n",
    "  conv1 = Conv1D(filters, 1, dilation_rate=d_rate, padding='same', kernel_regularizer=l2(0.001))(act1)\n",
    "\n",
    "  #bottleneck convolution\n",
    "  bn2 = BatchNormalization()(conv1)\n",
    "  act2 = Activation('relu')(bn2)\n",
    "  conv2 = Conv1D(filters, 3, padding='same', kernel_regularizer=l2(0.001))(act2)\n",
    "\n",
    "  #skip connection\n",
    "  x = Add()([conv2, shortcut])\n",
    "\n",
    "  return x\n",
    "\n",
    "train_ohe = to_categorical(train_pad)\n",
    "val_ohe = to_categorical(val_pad)\n",
    "test_ohe = to_categorical(test_pad)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7d4f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "train_ohe=train_ohe.astype(np.bool_)\n",
    "val_ohe=val_ohe.astype(np.bool_)\n",
    "test_ohe=test_ohe.astype(np.bool_)\n",
    "\n",
    "train_ohe=np.reshape(train_ohe, (1086741,-1))\n",
    "val_ohe=np.reshape(val_ohe, (126171,-1))\n",
    "test_ohe=np.reshape(test_ohe, (126171,-1))\n",
    "\n",
    "train_ohe_sp=sparse.csr_matrix(train_ohe) # 采用行优先的方式压缩矩阵\n",
    "sparse.save_npz('train_ohe_2048.npz',train_ohe_sp)  # 保存稀疏矩阵\n",
    "\n",
    "val_ohe_sp=sparse.csr_matrix(val_ohe) # 采用行优先的方式压缩矩阵\n",
    "sparse.save_npz('val_ohe_2048.npz',val_ohe_sp) \n",
    "\n",
    "test_ohe_sp=sparse.csr_matrix(test_ohe) # 采用行优先的方式压缩矩阵\n",
    "sparse.save_npz('test_ohe_2048.npz',test_ohe_sp) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4178cf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_ohe.shape,val_ohe.shape,test_ohe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cb3b221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1086741, 17929) (126171, 17929)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape,y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4091c8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train.astype(np.bool_)\n",
    "y_val=y_val.astype(np.bool_)\n",
    "y_test=y_test.astype(np.bool_)\n",
    "\n",
    "y_train_sp=sparse.csr_matrix(y_train) # 采用行优先的方式压缩矩阵\n",
    "sparse.save_npz('y_train_2048.npz',y_train_sp)  # 保存稀疏矩阵\n",
    "\n",
    "y_val_sp=sparse.csr_matrix(y_val) # 采用行优先的方式压缩矩阵\n",
    "sparse.save_npz('y_val_2048.npz',y_val_sp) \n",
    "\n",
    "\n",
    "y_test_sp=sparse.csr_matrix(y_test) # 采用行优先的方式压缩矩阵\n",
    "sparse.save_npz('y_test_2048.npz',y_test_sp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69cc2c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<126171x17929 sparse matrix of type '<class 'numpy.bool_'>'\n",
       "\twith 126171 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344326f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}